<html>
<head>
<title>Google shows off concepts for "socially intelligent" smart displays with Soli</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>谷歌用 Soli 展示了“社交智能”智能显示器的概念</h1>
<blockquote>原文：<a href="https://www.xda-developers.com/google-atap-soli-concept/#0001-01-01">https://www.xda-developers.com/google-atap-soli-concept/#0001-01-01</a></blockquote><div><div class="content-block-regular">
<p>谷歌的高级技术和项目组，也称为 ATAP，是谷歌内部的主要研发小组之一。ATAP 最初开发了 Soli 传感器，该传感器使用雷达识别手势，后来被纳入 Pixel 4 系列和谷歌 Nest Hub Max。现在我们来看看 ATAP 目前正在做什么，这要归功于一个新的 YouTube 视频。</p>

  
<p>Google ATAP 目前正在制作一个名为“在实验室中使用 Google ATAP”的纪录片系列，该团队在其中展示了其最新的研究成果。第一个视频探索了“如何结合新的传感和机器学习技术来捕捉我们手指的亚毫米运动，以创建富有表现力的微妙手势，从而与各种产品进行交互。”</p>

<p>\ r \ nht TPS://www . YouTube . com/watch？v=r-eh2K4HCzI\r\n</p>

<p>简单来说，ATAP 希望使用 Soli 传感器来检测细微的头部运动。该视频展示了一个智能显示屏，当有人走开时，它会暂停视频，或者当有人转头看设备时，它会用额外的天气信息更新屏幕。谷歌表示，其机器学习技术可以“估计头部方向”，这为更令人印象深刻的交互打开了大门。</p>

<p>没有人知道这种技术何时或是否会出现在商业产品中。谷歌目前唯一配备 Soli 传感器的产品是 Nest Hub Max，它使用 Soli 进行物体跟踪和人脸检测。Pixel 4 和 Pixel 4 XL 是仅有的带有 Soli 的手机——谷歌在 2020 年移除了 Pixel 5 的传感器，以降低制造成本(和边框)，Pixel 6 和 Pixel 6 Pro 也没有 Soli。</p>

<p>ATAP 也是 Project Ara 背后的团队，这是一个可定制和模块化智能手机设计的早期尝试。Ara 项目旨在为相机、存储器、显示器和其他组件创建模块，这些模块可以根据需要进行交换和升级。</p>

<p><strong> Via: </strong> <a href="https://9to5google.com/2022/03/01/google-soli-future-gestures/"> 9to5Google </a></p>

 </div>


</div>    
</body>
</html>